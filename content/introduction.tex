\chapter{Einleitung}

\section{Project Tango}

Project Tango ist ein Android Tablet und Smartphone Projekt von Google’s Advanced Technology and Projects Group (ATAP). Es ermöglicht in erster Linie ein Tracking von Positionsänderungen des Geräts im Raum und bietet somit eine genaue relative Lokalisierung. Mit Hilfe dieser Lokalisierung und der Hinzunahme von visuellen Merkmalen im Raum, ist das Gerät in der Lage, seine Umgebung kennenzulernen und gegebenenfalls seine Lokalisierung zu korrigieren oder aber in einer bereits erlernten Umgebung zu ermitteln. Zusätzlich bietet Project Tango die Möglichkeit mit Hilfe eines Tiefensensors eine Pointcloud der Tiefeninformation pro Bildausschnitt zu liefern, um Anwendungen auch Räumliche Informationen bereitzustellen. Das Ziel dieser Plattform ist es Motion Tracking (Positionierung), Depth Perception (Tiefeninformation/Pointcloud) und Area Learning (Lokalisierung) auf mobile Endgeräte zu bringen, um verschiedene Anwendungs-Szenarien abzudecken. Typische Szenarien sind Indoor Navigation, Virtual Reality Anwendungen, Vermessungs- und Rekonstruktions Software und Augmented Reality Anwendungen.

\section{Augmented Reality}

Der Fokus dieser Forschungsarbeit liegt hier auf dem Anwendungsbereich Augmented Reality (AR). Typischerweise wird in mobilen AR Anwendungen meist das Kamerabild analysiert und virtuelle Objekte anhand von Features oder Marker im Bild positioniert. Andere Sensoren wie Kompass, INS oder GPS können eine grobe Lokalisation ohne Marker ermöglichen, führen aber langfristig zu Fehlern, wenn keine optischen Referenzen gegeben sind. Mit Hilfe von Motion Tracking mit Project Tango kann diese Lokalisierung von virtuellen Objekten im Raum meist zuverlässig ohne vordefinierte Marker realisiert werden. Zudem gibt es die Möglichkeit auch die Pointcloud der Tiefensensoren zu nutzen, um die AR Anwendung näher an den echten räumlichen Gegebenheiten anzupassen. Hierzu existieren bereits prototypische Anwendungen, in denen virtuelle Markierungen passend an echten Objekten im virtuellen Raum positioniert werden können, indem Sie auf die aktuellen Tiefeninformation der Tiefensensoren zurückgreifen. Einige Beispiele zeigen auch die grobe Rekonstruktion aus der Pointcloud, um zum Beispiel ein einfaches 3D Spielfeld im Raum zu bestimmen.

Um dem Nutzer in AR Anwendungen Spielflächen anbieten zu können, Überdeckungen von virtuellen Objekten mit reellen Objekten im Raum zu ermöglichen und geometrische Mechanismen, wie zum Beispiel Kollisionen, nutzen zu können, ist es wichtig räumliche Informationen der Umgebung aus der Pointcloud zu gewinnen. Diese Forschungsarbeit soll sich damit beschäftigen, welche Algorithmik genutzt werden kann, um diese räumlichen Informationen gewinnen zu können, um wiederum das AR Erlebnis zu verbessern. 

\section{Fragestellung der Forschungsarbeit}

Die erste Fragestellung richtet sich dem Thema, wie man performant und automatisiert geometrische Primitiven in einer Pointcloud finden kann. Dazu soll zunächst eine Literaturrecherche bezüglich bekannter Methoden und Algorithmen durchgeführt werden, welche darauf folgend anhand gestellter Kriterien entsprechend evaluiert werden. Für diese Evaluation ist auch die Erstellung einer einheitlichen, zum AR Anwendungsfall passenden, Testumgebung denkbar. Letztendlich soll eine prototypische Implementierung dieser Primitiven Detektion erstellt werden, auf der im späteren Verlauf aufgebaut werden kann.

Später soll bestimmt werden ob und wie sich diese gefundenen Primitiven im Nachhinein oder im Verlauf einer Anwendung selbstständig verbessern oder optimieren lassen, oder ob die Basisdaten (Pointcloud) entsprechend verbessert werden können. Hierzu soll näher untersucht werden ob die Bildinformationen aus der Project Tango Kamera dabei helfen können durch zum Beispiel Kantenerkennung eine Optimierung vorzunehmen. Die hieraus gewonnen Erkenntnisse sollen genutzt werden, um den zuvor implementierten Prototypen weiter zu verbessern.