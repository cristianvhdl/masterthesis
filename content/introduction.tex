\chapter{Einleitung}

Die mobile Plattform von Googles Advanced Technology and Projects (ATAP) Team mit dem Namen Project Tango, bietet die Verfügbarkeit von Technologien zur Bewegungsverfolgung, der Tiefenwahrnehmung und dem Lernprozess, die Umgebung kennenzulernen, auf mobilen Endgeräten. 

\begin{quotation}
\enquote{Project Tango combines 3D motion tracking with depth sensing to give your mobile device the ability to know where it is and how it moves through space.}  \citep{Proje19:online}
\end{quotation}

Diese Verfügbarkeit ermöglicht viele verschiedene neue Einsatzmöglichkeiten auf mobilen Endgeräten wie Smartphones und Tablets. Typische Einsatzszenarien dieser Plattform sind die Indoor Navigation, die Vermessung der Umgebung sowie andere typische Anwendungen für Virtual und Augmented Reality. \\

Der Fokus dieser Forschungsarbeit liegt hier auf dem Anwendungsbereich Augmented Reality (AR). Typischerweise wird in mobilen AR Anwendungen meist das aufgenommene Kamerabild analysiert und virtuelle Objekte anhand von Features oder Marker im Bild positioniert. Andere Sensoren wie Kompass, INS (Trägheitsnavigationssystem) oder GPS können eine grobe Lokalisation ohne Marker ermöglichen, führen aber langfristig zu Fehlern, wenn keine optischen Referenzen gegeben sind. Mit Hilfe von der Bewegungsverfolgung durch Project Tango kann diese Lokalisierung des Gerätes und somit die korrekte Positionierung von virtuellen Objekten im Raum deutlich zuverlässiger und ohne vordefinierte Marker realisiert werden. 

\section{Fragestellung der Forschungsarbeit}

Die Project Tango Plattform bietet die Möglichkeit auch die Tiefeninformationen der Tiefensensoren zu nutzen, um die Augmented Reality Anwendung näher an die echten räumlichen Gegebenheiten anzupassen. Es existieren zum Beispiel prototypische Anwendungen, in denen virtuelle Markierungen passend an echten Objekten im virtuellen Raum positioniert werden können, indem sie auf die aktuellen Tiefeninformation des Sichtbereichs zurückgreifen.\\

Um dem Nutzer in AR Anwendungen Spielflächen anbieten zu können, Überdeckungen von virtuellen Objekten mit reellen Objekten im Raum zu ermöglichen und geometrische Mechanismen, wie zum Beispiel Kollisionen, nutzen zu können, ist es wichtig räumliche Informationen der Umgebung aus der Pointcloud zu gewinnen, die zur Interpretation dieser Mechanismen notwendig sind. Diese Forschungsarbeit beschäftigen sich damit, welche Algorithmik genutzt werden kann, um diese räumlichen Informationen einer Szene gewinnen zu können, um wiederum das Augmented Reality Erlebnis zu verbessern.\\


%Die erste Fragestellung richtet sich dem Thema, wie man performant und automatisiert geometrische Primitiven in einer Szene finden kann. Dazu soll zunächst eine Literaturrecherche bezüglich bekannter Methoden und Algorithmen durchgeführt werden, welche darauf folgend anhand gestellter Kriterien entsprechend evaluiert werden. Für diese Evaluation ist auch die Erstellung einer einheitlichen, zum AR Anwendungsfall passenden, Testumgebung denkbar. Letztendlich soll eine prototypische Implementierung dieser Primitiven Detektion erstellt werden, auf der im späteren Verlauf aufgebaut werden kann.\\

%Später soll bestimmt werden ob und wie sich diese gefundenen Primitiven im Nachhinein oder im Verlauf einer Anwendung selbstständig verbessern oder optimieren lassen, oder ob die Basisdaten (Pointcloud) entsprechend verbessert werden können. Hierzu soll näher untersucht werden ob die Bildinformationen aus der Project Tango Kamera dabei helfen können durch zum Beispiel Kantenerkennung eine Optimierung vorzunehmen. Die hieraus gewonnen Erkenntnisse sollen genutzt werden, um den zuvor implementierten Prototypen weiter zu verbessern.\\



\section{Vorgehen}